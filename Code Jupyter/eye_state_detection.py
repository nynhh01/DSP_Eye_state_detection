# -*- coding: utf-8 -*-
"""ExampleEEG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Kne4JzZE-wgyNbq4eSojcu1w1oky8y8w
"""

!pip install liac-arff

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from scipy.signal import butter, filtfilt
import numpy as np
from scipy.linalg import eigh
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import xgboost as xgb

from google.colab import files
import pandas as pd
import arff

uploaded = files.upload()


file_path = list(uploaded.keys())[0]

with open(file_path, 'r') as f:
    dataset = arff.load(f)

data = pd.DataFrame(dataset['data'], columns=[attr[0] for attr in dataset['attributes']])

# Bước 5: Hiển thị thông tin dataset
print(data.head())

data

df = data

# define sampling rate, time vector, and electrode list (columns list)
Fs = 128 # (number of samples / 117s length of data mentioned on the data description) rounded to the closest integer.
t = np.arange(0, len(df) * 1 / Fs, 1/Fs)
cols = df.columns.tolist()[:-1]

print( 'Number of null samples:\n' + str(df.isnull().sum()) )
df.head()

# separate targets so you can preprocess the EEG data easily
Y = df['eyeDetection']
print( Y.shape )

X = df.drop(columns='eyeDetection')
print( X.shape )
X.head()

def plot_data(X, xlim=[0, 20]):
    plt.figure(figsize=(15, 12))
    num_signals = len(X[0].columns.tolist())  # Số tín hiệu
    y_ticks = []  # Vị trí các nhãn trên trục y
    y_labels = []  # Nhãn của các tín hiệu

    for ind_data, data in enumerate(X):
        for ind, col in enumerate(data.columns.tolist()):
            y_offset = 5 * ind
            plt.plot(t, y_offset + stats.zscore(data[col], nan_policy='omit'),
                     linewidth=0.5 if ind_data == len(X) - 1 else 0.3,
                     alpha=1 if ind_data == len(X) - 1 else 0.6,
                     label=col if ind_data == len(X) - 1 else None,
                     color='k' if ind_data < len(X) - 1 else None)

            if ind_data == len(X) - 1:
                y_ticks.append(y_offset)  # Lưu vị trí để đặt nhãn
                y_labels.append(col)      # Lưu tên tín hiệu

    # Đặt nhãn cho trục y
    plt.yticks(y_ticks, y_labels)
    plt.xlim(xlim)
    plt.xlabel('Time (s)')
    plt.ylabel('Signals')
    plt.title('EEG Signals with Labels')
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.tight_layout()

# Find outliers and put Nan instead
X = X.apply(stats.zscore, axis=0)
X = X.applymap(lambda x: np.nan if (abs(x) > 4) else x )

# recalculate outliers with ignoring nans since the first calculation was biased with the huge outliers!
X = X.apply(stats.zscore, nan_policy='omit', axis=0)
X = X.applymap(lambda x: np.nan if (abs(x) > 4) else x )

plot_data([X])

from scipy import signal, interpolate

def interp(x):
    t_temp = t[ x.index[ ~x.isnull() ] ]
    x = x[ x.index[ ~x.isnull() ] ]
    clf = interpolate.interp1d(t_temp, x, kind='cubic')
    return clf(t)

# interpolate the nans using cubic spline method
X_interp = X.apply(interp, axis=0)

plot_data([X_interp])

# ICA
from sklearn.decomposition import FastICA

# apply ICA to drop non-electrophysiolgoical components (requires familiarity with EEG data)
ica = FastICA(max_iter=2000, random_state=0)
X_pcs = pd.DataFrame( ica.fit_transform(X_interp) )
X_pcs.columns = ['PC' + str(ind+1) for ind in range(X_pcs.shape[-1])]

plot_data([X_pcs], xlim=[0, 120])
X_pcs = X_pcs.drop(columns=['PC1', 'PC7'])
# reconstruct clean EEG after dropping the bad components
ica.mixing_ = np.delete(ica.mixing_, [0, 6], axis = 1)
X_interp_clean = pd.DataFrame( ica.inverse_transform(X_pcs) )
X_interp_clean.columns = cols

plot_data([X_interp, X_interp_clean], xlim=[0, 20])

X_interp_clean.shape

X_interp_clean = X_interp

# now that data is clean, extract alpha waves magnitude from the clean signals

# filter the data between 8-12 Hz (note that data has been rescaled to original scale after filtering for comparable visualization)
b, a = signal.butter(6, [8 / Fs * 2, 12 / Fs * 2], btype='bandpass')
X_interp_clean_alpha = X_interp_clean.apply(lambda x: signal.filtfilt(b, a, x) / max(abs(signal.filtfilt(b, a, x))) * max(abs(x)), axis=0)

# extract envelope of the Alpha waves
X_interp_clean_alpha = X_interp_clean_alpha.apply(lambda x: np.abs(signal.hilbert(x)), axis=0)
X_interp_clean_alpha.columns = cols

plot_data([X_interp_clean, X_interp_clean_alpha], xlim=[0, 20])

X_interp_clean_alpha.shape

# drop features with high correlations
X = X_interp_clean_alpha
Cols_corr = X.corr()

# plot correlations of the cols
plt.figure( figsize=(10,10) )
sns.heatmap(Cols_corr, annot=True, annot_kws={'fontsize':12})

# train an SVM to classify
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler

# split train test data
X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=48, test_size=0.2, stratify=Y, shuffle=True)

# normalize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

Y = Y.astype(int)
y_train = y_train.astype(int)
y_test = y_test.astype(int)

# Define a function to compute CSP filters
def compute_csp(X, y, n_components=14):
    # Separate EEG trials for each class
    class_0 =np.transpose(X[y == 0])
    class_1 =np.transpose(X[y == 1])

    # Compute class-wise covariance matrices
    cov_0 = np.dot(class_0,np.transpose(class_0))/np.trace(np.dot(class_0,np.transpose(class_0)))
    cov_1 = np.dot(class_1,np.transpose(class_1))/np.trace(np.dot(class_1,np.transpose(class_1)))


    # Compute generalized eigenvalues and eigenvectors
    eigenvalues, eigenvectors = eigh(cov_0, cov_0 + cov_1)

    # Sort eigenvectors based on eigenvalues
    sorted_indices = np.argsort(eigenvalues)[::-1]
    sorted_eigenvectors = eigenvectors[:, sorted_indices]

    # Select top CSP filters
    csp_filters = sorted_eigenvectors[:, :n_components]

    return csp_filters

# Define a function to apply CSP filtering to EEG signals
def apply_csp(X, csp_filters):
    return np.dot(csp_filters.T, X.T).T  # Transpose X before applying filters and transpose the result back

# Compute CSP filters
csp_filters = compute_csp(X_train, y_train)
# Apply CSP filtering to training and testing data
X_train_csp = apply_csp(X_train, csp_filters)
X_test_csp = apply_csp(X_test, csp_filters)

# Initialize KNN classifier
knn_classifier = KNeighborsClassifier(n_neighbors=5, metric="minkowski", p=2)  # You can adjust the number of neighbors as needed

# Train the KNN classifier on the CSP-filtered training data
knn_classifier.fit(X_train_csp, y_train)

# Make predictions on the CSP-filtered training data
y_train_pred = knn_classifier.predict(X_train_csp )

# Make predictions on the CSP-filtered test data
y_test_pred = knn_classifier.predict(X_test_csp)

# Calculate training accuracy
train_accuracy = accuracy_score(y_train, y_train_pred)
print("Training Accuracy:", train_accuracy)

# Calculate test accuracy
test_accuracy = accuracy_score(y_test, y_test_pred)
print("Test Accuracy:", test_accuracy)

# Print classification report for test data
print("Test Classification Report:")
print(classification_report(y_test, y_test_pred))

# Calculate and print confusion matrix for test data
conf_matrix = confusion_matrix(y_test, y_test_pred)
print("Confusion Matrix:")
print(conf_matrix)



import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix


# Vẽ heatmap cho ma trận confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])  # Đổi nhãn nếu cần

# Thêm nhãn và tiêu đề
plt.xlabel('Predicted Labels', fontsize=12)
plt.ylabel('True Labels', fontsize=12)
plt.title('Confusion Matrix', fontsize=14)
plt.show()

from sklearn.metrics import roc_auc_score

# train with grid search
svc = SVC()
parameters = {'gamma': [0.1, 1, 10], 'C': [0.1, 1, 10]}
clf = GridSearchCV(svc, parameters)
clf.fit(X_train_csp, y_train)

# predict labels
y_test_pred = clf.predict(X_test_csp)

# Calculate training accuracy
train_accuracy = accuracy_score(y_train, y_train_pred)
print("Training Accuracy:", train_accuracy)

# Calculate test accuracy
test_accuracy = accuracy_score(y_test, y_test_pred)
print("Test Accuracy:", test_accuracy)

# Print classification report for test data
print("Test Classification Report:")
print(classification_report(y_test, y_test_pred))

# Calculate and print confusion matrix for test data
conf_matrix = confusion_matrix(y_test, y_test_pred)
print("Confusion Matrix:")
print(conf_matrix)



import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix


# Vẽ heatmap cho ma trận confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])  # Đổi nhãn nếu cần

# Thêm nhãn và tiêu đề
plt.xlabel('Predicted Labels', fontsize=12)
plt.ylabel('True Labels', fontsize=12)
plt.title('Confusion Matrix', fontsize=14)
plt.show()

# Initialize Random Forest classifier
rf_classifier = RandomForestClassifier(n_estimators=1000, random_state=42)

# Train the Random Forest classifier on the CSP-filtered training data
rf_classifier.fit(X_train_csp, y_train)

# Make predictions on the CSP-filtered training data
y_train_pred = rf_classifier.predict(X_train_csp)

# Calculate training accuracy
train_accuracy = accuracy_score(y_train, y_train_pred)
print("Training Accuracy:", train_accuracy)

# Make predictions on the CSP-filtered test data
y_test_pred = rf_classifier.predict(X_test_csp)

# Calculate testing accuracy
test_accuracy = accuracy_score(y_test, y_test_pred)
print("Testing Accuracy:", test_accuracy)

print("Classification Report:")
print(classification_report(y_test, y_test_pred))
# Calculate and print confusion matrix for test data
conf_matrix = confusion_matrix(y_test, y_test_pred)
print("Confusion Matrix:")
print(conf_matrix)

# Vẽ heatmap cho ma trận confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])  # Đổi nhãn nếu cần

# Thêm nhãn và tiêu đề
plt.xlabel('Predicted Labels', fontsize=12)
plt.ylabel('True Labels', fontsize=12)
plt.title('Confusion Matrix', fontsize=14)
plt.show()

import joblib
from google.colab import files


joblib.dump(knn_classifier, 'knn_model.joblib')

files.download('knn_model.joblib')

# Combine X and Y into one DataFrame
X_combined = pd.concat([pd.DataFrame(X_test_csp), y_test.reset_index(drop=True)], axis=1) # Convert X_train_csp to a DataFrame and reset index of y_train for proper alignment

# Save the combined DataFrame to an Excel file
output_file = '/content/eeg_data_combined.xlsx'
X_combined.to_excel(output_file, index=False)

# Download the Excel file to your local machine
files.download(output_file)